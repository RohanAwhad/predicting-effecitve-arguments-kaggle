{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0b652721",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-d21a66f731a0ac2e\n",
      "Reusing dataset parquet (/home/rohan/.cache/huggingface/datasets/parquet/default-d21a66f731a0ac2e/0.0.0/7328ef7ee03eaf3f86ae40594d46a1cec86161704e02dd19f232d81eee72ade8)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96766ac129e7487b8e84d0105a724c4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-e9189d029ccbfb66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset parquet/default to /home/rohan/.cache/huggingface/datasets/parquet/default-e9189d029ccbfb66/0.0.0/7328ef7ee03eaf3f86ae40594d46a1cec86161704e02dd19f232d81eee72ade8...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d7846c4ace24643ae43ed812b82e526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37053b773db04d8497073b3f9990ceb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /home/rohan/.cache/huggingface/datasets/parquet/default-e9189d029ccbfb66/0.0.0/7328ef7ee03eaf3f86ae40594d46a1cec86161704e02dd19f232d81eee72ade8. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efab5f522de1431299c205ec1bd2a573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('parquet', data_files={'train': '../data/train_UPD.parquet'})\n",
    "sample_dataset = load_dataset('parquet', data_files={'train': '../data/sample_train.parquet', 'test': '../data/sample_test.parquet'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0b032be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'discourse_id': '0013cc385424',\n",
       " 'essay_id': '007ACE74B050',\n",
       " 'discourse_text': \"Hi, i'm Isaac, i'm going to be writing about how this face on Mars is a natural landform or if there is life on Mars that made it. The story is about how NASA took a picture of Mars and a face was seen on the planet. NASA doesn't know if the landform was created by life on Mars, or if it is just a natural landform. \",\n",
       " 'discourse_type': 'Lead',\n",
       " 'discourse_effectiveness': 'Adequate',\n",
       " 'discourse_text_UPD': \"Hi, i'm Isaac, i'm going to be writing about how this face on Mars is a natural landform or if there is life on Mars that made it. The story is about how NASA took a picture of Mars and a face was seen on the planet. NASA doesn't know if the landform was created by life on Mars, or if it is just a natural landform.\",\n",
       " 'essay_text': 'Hi, i\\'m Isaac, i\\'m going to be writing about how this face on Mars is a natural landform or if there is life on Mars that made it. The story is about how NASA took a picture of Mars and a face was seen on the planet. NASA doesn\\'t know if the landform was created by life on Mars, or if it is just a natural landform. On my perspective, I think that the face is a natural landform because I dont think that there is any life on Mars. In these next few paragraphs, I\\'ll be talking about how I think that is is a natural landform\\n\\nI think that the face is a natural landform because there is no life on Mars that we have descovered yet. If life was on Mars, we would know by now. The reason why I think it is a natural landform because, nobody live on Mars in order to create the figure. It says in paragraph 9, \"It\\'s not easy to target Cydonia,\" in which he is saying that its not easy to know if it is a natural landform at this point. In all that they\\'re saying, its probably a natural landform.\\n\\nPeople thought that the face was formed by alieans because they thought that there was life on Mars. though some say that life on Mars does exist, I think that there is no life on Mars.\\n\\nIt says in paragraph 7, on April 5, 1998, Mars Global Surveyor flew over Cydonia for the first time. Michael Malin took a picture of Mars with his Orbiter Camera, that the face was a natural landform. Everyone who thought it was made by alieans even though it wasn\\'t, was not satisfied. I think they were not satisfied because they have thought since 1976 that it was really formed by alieans.\\n\\nThough people were not satified about how the landform was a natural landform, in all, we new that alieans did not form the face. I would like to know how the landform was formed. we know now that life on Mars doesn\\'t exist.             ',\n",
       " 'essay_text_UPD': 'Hi, i\\'m Isaac, i\\'m going to be writing about how this face on Mars is a natural landform or if there is life on Mars that made it. The story is about how NASA took a picture of Mars and a face was seen on the planet. NASA doesn\\'t know if the landform was created by life on Mars, or if it is just a natural landform. On my perspective, I think that the face is a natural landform because I dont think that there is any life on Mars. In these next few paragraphs, I\\'ll be talking about how I think that is is a natural landform\\n\\nI think that the face is a natural landform because there is no life on Mars that we have descovered yet. If life was on Mars, we would know by now. The reason why I think it is a natural landform because, nobody live on Mars in order to create the figure. It says in paragraph 9, \"It\\'s not easy to target Cydonia,\" in which he is saying that its not easy to know if it is a natural landform at this point. In all that they\\'re saying, its probably a natural landform.\\n\\nPeople thought that the face was formed by alieans because they thought that there was life on Mars. though some say that life on Mars does exist, I think that there is no life on Mars.\\n\\nIt says in paragraph 7, on April 5, 1998, Mars Global Surveyor flew over Cydonia for the first time. Michael Malin took a picture of Mars with his Orbiter Camera, that the face was a natural landform. Everyone who thought it was made by alieans even though it wasn\\'t, was not satisfied. I think they were not satisfied because they have thought since 1976 that it was really formed by alieans.\\n\\nThough people were not satified about how the landform was a natural landform, in all, we new that alieans did not form the face. I would like to know how the landform was formed. we know now that life on Mars doesn\\'t exist.',\n",
       " 'labels': 1}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b895a4e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36765"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "4f3db46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "https://huggingface.co/distilbert-base-uncased/resolve/main/tokenizer_config.json not found in cache or force_download set to True, downloading to /home/rohan/.cache/huggingface/transformers/tmpmn8hcb7s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c42079962e434736932d7103aaf3236b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/distilbert-base-uncased/resolve/main/tokenizer_config.json in cache at /home/rohan/.cache/huggingface/transformers/8c8624b8ac8aa99c60c912161f8332de003484428c47906d7ff7eb7f73eecdbb.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "creating metadata file for /home/rohan/.cache/huggingface/transformers/8c8624b8ac8aa99c60c912161f8332de003484428c47906d7ff7eb7f73eecdbb.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "https://huggingface.co/distilbert-base-uncased/resolve/main/config.json not found in cache or force_download set to True, downloading to /home/rohan/.cache/huggingface/transformers/tmpbzfm8ebk\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f97a144f31542ad8a75f0eb63a03cd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/distilbert-base-uncased/resolve/main/config.json in cache at /home/rohan/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
      "creating metadata file for /home/rohan/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /home/rohan/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "https://huggingface.co/distilbert-base-uncased/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /home/rohan/.cache/huggingface/transformers/tmpyef16add\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16e452c52b4245ad9297c2558dc363b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/distilbert-base-uncased/resolve/main/vocab.txt in cache at /home/rohan/.cache/huggingface/transformers/0e1bbfda7f63a99bb52e3915dcf10c3c92122b827d92eb2d34ce94ee79ba486c.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "creating metadata file for /home/rohan/.cache/huggingface/transformers/0e1bbfda7f63a99bb52e3915dcf10c3c92122b827d92eb2d34ce94ee79ba486c.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "https://huggingface.co/distilbert-base-uncased/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /home/rohan/.cache/huggingface/transformers/tmp4k9smz21\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a49ee36a8c144bce9919fc6d3e8ac874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/distilbert-base-uncased/resolve/main/tokenizer.json in cache at /home/rohan/.cache/huggingface/transformers/75abb59d7a06f4f640158a9bfcde005264e59e8d566781ab1415b139d2e4c603.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "creating metadata file for /home/rohan/.cache/huggingface/transformers/75abb59d7a06f4f640158a9bfcde005264e59e8d566781ab1415b139d2e4c603.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/vocab.txt from cache at /home/rohan/.cache/huggingface/transformers/0e1bbfda7f63a99bb52e3915dcf10c3c92122b827d92eb2d34ce94ee79ba486c.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/tokenizer.json from cache at /home/rohan/.cache/huggingface/transformers/75abb59d7a06f4f640158a9bfcde005264e59e8d566781ab1415b139d2e4c603.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/rohan/.cache/huggingface/transformers/8c8624b8ac8aa99c60c912161f8332de003484428c47906d7ff7eb7f73eecdbb.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /home/rohan/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /home/rohan/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /home/rohan/.cache/huggingface/transformers/tmpuakiy98q\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac2c58fa4384b6cafa51f6f91d72c8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/256M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "storing https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin in cache at /home/rohan/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "creating metadata file for /home/rohan/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/rohan/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model_path = \"distilbert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b6ed21af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/gpt2/resolve/main/vocab.json from cache at /home/rohan/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
      "loading file https://huggingface.co/gpt2/resolve/main/merges.txt from cache at /home/rohan/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/gpt2/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/gpt2/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/gpt2/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /home/rohan/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /home/rohan/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "Model config GPT2Config {\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/gpt2/resolve/main/pytorch_model.bin from cache at /home/rohan/.cache/huggingface/transformers/752929ace039baa8ef70fe21cdf9ab9445773d20e733cf693d667982e210837e.323c769945a351daa25546176f8208b3004b6f563438a7603e7932bae9025925\n",
      "All model checkpoint weights were used when initializing GPT2ForSequenceClassification.\n",
      "\n",
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# from transformers import GPT2Tokenizer, GPT2ForSequenceClassification\n",
    "\n",
    "# model_path = 'gpt2'\n",
    "\n",
    "# tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
    "# model = GPT2ForSequenceClassification.from_pretrained(model_path, num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "dd4515cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "# model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5efb15",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7c16ce9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"discourse_text_UPD\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "64c0d6e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac07e9adeab40a2952f689ea7591a67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/rohan/.cache/huggingface/datasets/parquet/default-e9189d029ccbfb66/0.0.0/7328ef7ee03eaf3f86ae40594d46a1cec86161704e02dd19f232d81eee72ade8/cache-bdd640fb06671ad1.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = sample_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d7bcade9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokenized_dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b1a5849b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "38b25ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1036abd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'discourse_id': ['2770ee004949',\n",
       "  '4880cb5ba7a0',\n",
       "  '120eb7ef0397',\n",
       "  '73d6620df79f',\n",
       "  'cb2feb45ad42',\n",
       "  '3298b1d97f1b',\n",
       "  'f1978838407c',\n",
       "  '83adff3c950c',\n",
       "  'cbcfe2f6c748',\n",
       "  'a8de05bd08bb'],\n",
       " 'essay_id': ['A8683674019F',\n",
       "  'B0ED18C04F15',\n",
       "  'AE37AE3F79C7',\n",
       "  '95DC8A3C2EFD',\n",
       "  '68B6142F4EA9',\n",
       "  '91B00B44402B',\n",
       "  'E481765F7DDF',\n",
       "  '7A0F4648B341',\n",
       "  'FAF91DDF582C',\n",
       "  '5976F16FE9D2'],\n",
       " 'discourse_text': ['The electoral College is as I have said it before is fair and equal to all the citizens in the United States. To take this away now would be a catastraphe, ',\n",
       "  'Yes, I think the candidate with the most votes should win ',\n",
       "  \"After the school year ends, students return to their homes feeling a great sense of relief that the school year is over, and that they're about to get a much needed break. However, just because school has stopped doesn't mean that learning should. Three entire months off is long time, and many students actually forget most of what they learned over the past year and need to be refreshed when they return to school. It would save everyone a lot of time if students came back to school with the last year's information still fresh in their minds. The simple solution to this problem is summer assignments. \",\n",
       "  'like get to meet knew people and some might even become very close to you. I am sure that if you, came to the program you would love it. You would have fun,free food,and a good place to sleep. Now some might lo0ve animals , and if u dont thats fine but im sure you would start to. they are kind,loving,and gental. This program might get u in shapeand fit,you will be caring and lifting things and im sure that will burn off some fat. ',\n",
       "  'The author tells in the text, \"We humans perform this same impressive calculation every day.\" But comparing a human mind to a computer is different. A human mind can think that the friend is feeling sad, but the computer can have more than just one idea of how the friend feels. The computer can have more than one idea by scanning the face of the person and calculating how the muscles of the face look ',\n",
       "  'Cell phones are a great source for entertainment as well as a social device ',\n",
       "  'As much as I hate to say it, there most definitley is an upside to the Electoral College. ',\n",
       "  'Mandatory participation in extracurricular activities is bad for students because the students may not have time, they might not be interested and they lose the ability to choose for themselves. It is important students that students have the right to choose so they know that there are always options. If students are forced to take extracurricular activites, they will become more disheartened, more weary and tired from balancing their social and academic lives along with sports and other classes, and wake up with less promise that they would have a good day. After all, we do need to nurture our students, as they are the future of the world, as the next generation. ',\n",
       "  \"the student's teacher will know what that person needs to work on. \",\n",
       "  'Traffic laws are written with the asssumption that the only safe car has a human driver in contral at all times (Ph. 9). As a result, many states restrict the use of driverless cars on the roads. '],\n",
       " 'discourse_type': ['Claim',\n",
       "  'Claim',\n",
       "  'Lead',\n",
       "  'Evidence',\n",
       "  'Evidence',\n",
       "  'Claim',\n",
       "  'Counterclaim',\n",
       "  'Concluding Statement',\n",
       "  'Claim',\n",
       "  'Evidence'],\n",
       " 'discourse_effectiveness': ['Adequate',\n",
       "  'Adequate',\n",
       "  'Effective',\n",
       "  'Adequate',\n",
       "  'Adequate',\n",
       "  'Adequate',\n",
       "  'Adequate',\n",
       "  'Effective',\n",
       "  'Adequate',\n",
       "  'Adequate'],\n",
       " 'discourse_text_UPD': ['The electoral College is as I have said it before is fair and equal to all the citizens in the United States. To take this away now would be a catastraphe,',\n",
       "  'Yes, I think the candidate with the most votes should win',\n",
       "  \"After the school year ends, students return to their homes feeling a great sense of relief that the school year is over, and that they're about to get a much needed break. However, just because school has stopped doesn't mean that learning should. Three entire months off is long time, and many students actually forget most of what they learned over the past year and need to be refreshed when they return to school. It would save everyone a lot of time if students came back to school with the last year's information still fresh in their minds. The simple solution to this problem is summer assignments.\",\n",
       "  'like get to meet knew people and some might even become very close to you. I am sure that if you, came to the program you would love it. You would have fun,free food,and a good place to sleep. Now some might lo0ve animals , and if u dont thats fine but im sure you would start to. they are kind,loving,and gental. This program might get u in shapeand fit,you will be caring and lifting things and im sure that will burn off some fat.',\n",
       "  'The author tells in the text, \"We humans perform this same impressive calculation every day.\" But comparing a human mind to a computer is different. A human mind can think that the friend is feeling sad, but the computer can have more than just one idea of how the friend feels. The computer can have more than one idea by scanning the face of the person and calculating how the muscles of the face look',\n",
       "  'Cell phones are a great source for entertainment as well as a social device',\n",
       "  'As much as I hate to say it, there most definitley is an upside to the Electoral College.',\n",
       "  'Mandatory participation in extracurricular activities is bad for students because the students may not have time, they might not be interested and they lose the ability to choose for themselves. It is important students that students have the right to choose so they know that there are always options. If students are forced to take extracurricular activites, they will become more disheartened, more weary and tired from balancing their social and academic lives along with sports and other classes, and wake up with less promise that they would have a good day. After all, we do need to nurture our students, as they are the future of the world, as the next generation.',\n",
       "  \"the student's teacher will know what that person needs to work on.\",\n",
       "  'Traffic laws are written with the asssumption that the only safe car has a human driver in contral at all times (Ph. 9). As a result, many states restrict the use of driverless cars on the roads.'],\n",
       " 'essay_text': ['Dear Senator\\n\\nThe Electoral College was created by our Founding Fathers. They put this in the Constitution to make electing the President of the United States fair and equal to all the citizens in the United States. The Electoral College should not be changed no matter what. To go against the Constitution would be to go against the nation, for we were built on the leadership of our Founding Fathers and the guidance of the Constitution. This Contitstution was created so that the people have more power than the government. So I strongly believe that the Electoral College should stay the same. It is the governmet that needs to change. There is nothing wrong with the Electoral College, it is just the ones that run it. So if there should be any change, it should be the government that should change, not the Electoral College!\\n\\nThe Ectoral College is a compromise between the election of the President by a vote in Congress and by the popular vote of the citizens. When the voting starts the electors come to a meeting place and vote on who they want as President. After the meeting, there has to be a majority of two hundred seventy electoral votes for the election of the president. The electoral College is as I have said it before is fair and equal to all the citizens in the United States. To take this away now would be a catastraphe, because that would mean that all the other presidents in the past would not have even been our Presidents, the history behind them would be rubish and not even true. Some states may have a \"winner-take-all\" sort of thing but they are together and voting together as on state. Some of them may vote for the other one but the majority of them is for one person. Some of the states believe that it is not even worth it to have a \"winner-take-all\", because they think it is unfair. Then after the presidential election comes the \"Certificate of Ascertainment\" which is a list of all those who ran for President and there respective electors.\\n\\nThe electoral college has been around ever since the Constitution was created. It may be unfair now, but if there would have been any changes to the Constitution it would have been done then instead of now. The Electoral College was probably a great idea when the the Constitution fisrt started out. Then the years have gone by and now we want change. Well I see that the Electoral College can be unfair but it is also fair in it\\'s own right. Because of the fiasco in the year of two thousand about the abolishment of the Electoral College, it has left a scare in our nation about the government, because you guys are giving out the information on the candidates to late or not at all. That SUCKS, for most states because they may not even get one advertisment about the candidates any where or even a commercial on T.V. If the vote for the abolishment of the Electoral College does happen, then there is nothing that I can do about it, but you can still change your ways. You can make it fair and not irrational. Even send the \"Certificate of Ascertainment\" earlier than you have done before now. This is a nation of freedom and peace, how are you trying to keep the peace with other countries if you can not even keep the peace within your own?\\n\\nThe government is the real problem, not the Electoral College. It may be unfair, because the majority of the people may have chosen one person while the electors may choose the other. Then when they add it together it is there vote that counts more than the peoples. If the government had only done the right thing and elected what the people wanted, then no one would have a problem with the Electoral College. It is stupid that the government is listening to what we have to say but not hearing it completly. The Constitution is a document of equality for the people. Not the government. If our nations democracy is a democracy then they should listen more to what the people have to say and not what the government has to say. If the government would do this then things would run more smoothly within our country and there would be less conflict.\\n\\nThis nation is a nation of freedom and peace. Not for a bunch of people who are power hungry. The Electoral College is fair and equal, it is the government that is not. If the government would only change for the better then there would be no problem. This nation is still young compared to all the other countries. They have gotten all there issues taken care of, but we have not. The reason is that some of the officials are power hungry and do things to take care of themselves and not others, but some are not and they want to make this country better. Those are the ones that should stay and not the power hungry ones. They make it fair. So I strongly belive that the Electoral College should stay the same, and that the government should be the one to change.\\n\\nFrome PROPER_NAME    ',\n",
       "  \"Dear State Senator,\\n\\nI read all these articles about some states having to vote for the president's electors. They say basically when your voting for a president, your voting for his/hers electors. My opinion is there should be no need for electors. It should be easy and not too complicated. A presdient, a vice president, and a secatary. No electors or nothing. I think a president can do alot of his own work and think of ideas alone. If he need help than instead of us wasting our time with voting for people to give the presdient ideas and help him out. Well the President always say's God Bless America. Shouldn't the President be listening to the voices of his country. America. Yes, I think the candidate with the most votes should win. But, If they say that their going to do something for our country than they need to keep their word. Make it a better place not for himslef but for everyone. For instance, Barack Obama. What's the need for this unessarcy work that he has done. America is loosing their mind and doesnt know what's going on. Why is he doing this? The president is to make smart decent relevant choices. And if he listen to the voices of Americans than he would have lots of ideas lots! Instead he listens to who? His electors. People complain saying to themselfs, Where does he come up with these ideas? Well if you payed close attention to the presidents background and know what he really wants to do than you would know why. Honestly to me I dont think the Electoral College should keep going its just a bunch of mess that just doesnt make sence. Elelctors dont matter to most American's. Take the electors and the Electoral College away we dont want something we dont need. All we need is a President, a Vice Presdient, and a Secatary.\\n\\nSencerely, America    \",\n",
       "  \"After the school year ends, students return to their homes feeling a great sense of relief that the school year is over, and that they're about to get a much needed break. However, just because school has stopped doesn't mean that learning should. Three entire months off is long time, and many students actually forget most of what they learned over the past year and need to be refreshed when they return to school. It would save everyone a lot of time if students came back to school with the last year's information still fresh in their minds. The simple solution to this problem is summer assignments. However, it is critically important that these summer assignments are student-designed, meaning that most of what is done for the assignment is thought of by the student rather than simply following the guidelines of their teacher. It is necessary that summer work be student-designed because it encourages and teaches self motivated learning, will be something the student is more passionate about, and will be less stress on teachers.\\n\\nThe first benefit of summer work being controlled by students is that it encourages and teaches self-motivated learning. Self-motivated learning is when the student has a desire to learn and therefore works hard to learn information without having to be pushed by their teachers. The truth is that while teachers can relay all the necessary information to students, if the students don't want anything to do with it they will learn far less effectively than students who do want to learn. By asking students to create their own summer assignment, it forces them into a new learning environment in which they have to take charge of their learning. Upon being put into this position, students will have to adapt to learn how to teach themselves information. This is a very valuble life skill that will be very helpful to them later in their lives, as self-education is needed for many things that are not taught in school as well as in the workplace. Motivating themselves is an important skill that can be taught through student-designed summer work.\\n\\nOn a similar note, giving students the ability to choose between what they have to do for their summer projects enables them to make the topic or submission format something that they are more passionate about than what they might otherwise be taught in school. Typically, in a learning context, more passion or excitement transfers to more success at whatever it is the students are trying to learn. Being more passionate about something causes people to interact with it much more, and interaction is key to the learning of many students. In addition, students being excited to do something furthers the self-motivation mentioned above. If there is something that a student wants to do, they will do it without needing a teacher to tell them to. Overall, the passion that comes from student-designed summer work makes it a much more fun and more effective experience for students.\\n\\nTo make things even better, student -designed summer work won't only be helping the students, it will be helping the teachers. Teachers work very hard to plan, produce, and grade all of the students' schoolwork for the entire school year. They deserve to have a break! By letting students take charge of their summer work, it takes an extra burden off the shoulders of the people who dedicated their lives to educating America's youth for a meager government salary. With the extra time they have without having to plan and construct a summer assignment, teachers can do many things, such as get the jump on later assignments that they will have to make, enjoy some time with their friends and family, or just get some much needed sleep. This extra time for teachers is another fantastic reason why summer assignments should be student-designed.\\n\\nThere is no doubt that summer assignments are a necessary part of learning, in order to continue to teach information and to help students remember information that they would otherwise forget. But these assignments should not be simple rubrics and reading notes, they should be something different. Something that is going to have a significant impact on everyone in the education system. Something that will build a strong new generation without overworking the old ones. Those who are students understand the value of enjoying and wanting to learn about a subject, those who are educators know how important it is to be able to motivate yourself to work, and those who are school teachers know that a little extra time and a little less stress goes a very long way. That is why summer assignments should be student designed rather than teacher-designed.\",\n",
       "  'The program Seagoing Cowboys ,is amazing even though u might of heard of it or not im going to try my best to make u want to be part of it. I say this because for example the program lets u go around the world,like in the story the said that Luke had travewled nine diffrent times. Isnt that great that could be you,of course if u would like to join.\\n\\nThere are lots of things that u could do there,like get to meet knew people and some might even become very close to you. I am sure that if you, came to the program you would love it. You would have fun,free food,and a good place to sleep. Now some might lo0ve animals , and if u dont thats fine but im sure you would start to. they are kind,loving,and gental. This program might get u in shapeand fit,you will be caring and lifting things and im sure that will burn off some fat.\\n\\nAlso if u come to the program,u would learn how to obay,clean,and be respectful. Im sure that a young mans mother would be happy to know that,they are cleaning, and obaying laws,and showing respecfulness. Oh and befor i forget, they also will be able to cook multipal meals for his family.\\n\\nThe lastly they will be cowboys,and thats a great thing to help out with the animals. The young men will be helping around with horses,and cows. I am sure that the young man, will enjoy the view of the world that hes traviling.\\n\\nI hope that you are convinced and made up your mind to let the young men come to this program. I am sure that youll enjoy it, till next time .',\n",
       "  'The use of this advanced technology to read the emotional expressions of students in a classroom is valuable from three reasons in the article that the author tells us by reading this article.\\n\\nIt\\'s interesting to think ahead and create something big that no one can do. In paragraph 3, the author says, \"The process begins when the computer constructs a 3-D computer model of the face; all 44 major muscles in the model must move like human muscles.\" The 44 muscles can tell how the human is feeling, by seeing how the person is moving. For example, when the person is moving really fast, it means that the person might be angry or aggressive. But when a person is moving slow, it means that the person is sad or depressed.\\n\\nThe author tells in the text, \"We humans perform this same impressive calculation every day.\" But comparing a human mind to a computer is different. A human mind can think that the friend is feeling sad, but the computer can have more than just one idea of how the friend feels. The computer can have more than one idea by scanning the face of the person and calculating how the muscles of the face look. It may seem amazing to try to use the technology.\\n\\nFrom the picture of Mona Lisa, when you just look at it, many ideas would pop up in your head from trying to guess how she\\'s feeling and how she looks. There would be multiple guesses on how her face looks. In paragraph 6, the author says, \"The Mona Lisa demonstration is really intended to bring a smile to your face, while it shows just how much this computer can do.\" Some people might say that she looks mostly happy, a bit disgusted, somewhat fearful, and a little angry. Or they might say all of them and more. We all have different minds, different thoughts, and a different sights at describing a picture.\\n\\nMoreover, the article gives us a lot of information of the advanced technological computer that constructs a 3-D model, to scan a human face and tell how the person feels emotionally. It\\'s amazing and interesting to even read about Dr. Huang and Prof. Sebe ,his colleague, are both experts at developing better ways for humans and computers to communicate.',\n",
       "  \"It may be true that some of us do abuse the fact that we are allowed cell phones at school. However, many of us respect our teachers and leave our phones turned off, only using them when permitted.\\n\\nIt would be a horrible and unfair thing to do for the school to take our phone privileges away. Many students may use them during class when they are supposed to be paying attention to their teachers, but not all students. Phones are a fun way to talk to our friends and family, even if they shouldn't be used during class.\\n\\nPhones are also great for emergencies, whether it's to call your parents about a school bus running late or if it's calling the police for a wanted criminal taking you hostage at the school. For this reason, new school policies could just be effecting the safety of the students. Many of us love our phones and would hate for our rights to be completely taken away.\\n\\nIn addition, some students need their phones. Protective parents may require their children to call or text them during break time to let them know they're doing okay.\\n\\nCell phones are a great source for entertainment as well as a social device. Some people can put music or games on their phones to listen to or play during the day. Anti-social students may like using this during break time and lunch time to entertain themselves.\\n\\nWhat harm would it do to allow students to use their phones during their lunch and break times? Class wouldn't be disrupted, teachers wouldn't be annoyed, and the students would still be able to have the phones that they enjoy using every day. By changing the phone policy, the school would be taking our rights away. This is also very unfair to those who use their phones outside of class. If we can't be trusted with phones only during our break times, then the school would be showing us great disrespect.                  \",\n",
       "  'Dear Senator,\\n\\nGood day, I am writing this letter to let you know it\\'s time for things to change. I have been reading and researching the Electoral College and i have a strong opinion on it. As you know, the Electoral College is a process when all five hundred and thirty eight electors vote on electors and defenders. This way of voting for electors lets the people have no say in whose running our goverment! Our goverment should not allow or be based on \"the winner takes all\" method. When we choose for OUR president we should be able to choose OUR electors too! Under the 23rd amendment of the constitution, the District of Columbia is allocated 3 electors and treated like a state for purposes of the electoral college. The electors shouldnt be chosen by the canidate\\'s political party, we should choose. By voting for a president every four years a new party of electors have already been selected to run with him and we dont get any say. After the presidential election, your governer creates a list of all the canidates that ran for president in your state with a list of their representative electors. This is later sent to Congress and the National Archives as part of the official records of the presidential election.\\n\\nRichard Nixon, Bob Dole, Jimmy Carter, the U.S. Chamber of Commerce, and the AFL-CIO all agree that we need to remove and forget about the electoral college. This year our voters can expect another close election in which the popular vote winner could lose the presidency. Still the electoral college still has defenders fror themselves is crazy. Facts say voters arent actually voting for the president, but for a group of electors who in turn elect the president, and that is ridiculous. How are we supposed to trust these electors if we dont even know who they are and their background until after the election? Who even are these electors i wondered. I figured out that all the electors are actually anyone with a brain and not holding a public office, fantastic. So how do i know they are reliable and going to do whats best for my state and our country? Voters dont even control whom their electors vote for most of the time which is kind of scary. Some electors are even faithless in their party\\'s canidate so they dont even vote for them at all! How can we rely on a group of people who dont rely on their party?\\n\\nAs much as I hate to say it, there most definitley is an upside to the Electoral College. The Electoral College is widely regarded as an anachronism, a non-democratic method of selecting a president that needs to be overruled by declaring the canidate who receives the most popular votes the winner. I personally think that is the best way to decide who gets in. Each party selects a slate of electors that are trusted to vote for the party\\'s nominee. Sometimes the electoral vote will not win the national popular vote. Another reason The Electoral College is a positive way of voting is how certain the outcome is. There is never failure in the counting of the votes and there us rarely a tie between two people. My favorite reason is because \"everybody is president\". This means everybody can make their own decisions and have a great amount of freedom.\\n\\nEven though im all for removing the Electoral College there is positives too. In a few years when i am able to vote, i will be careful of who I vote for and make sure that there is great electors in the party i vote for. \\xa0\\xa0\\xa0\\xa0       \\xa0 \\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0    ',\n",
       "  \"Extracurricular activities are fun. We can play sports after school, join different clubs, or play some games with other students. But we always get to choose what we want to do, right?\\n\\nMandatory participation in extracurricular activities is not good for students because they may not have time to stay after (jobs, other classes, homework, sports) , they might not be interested in any of the activities offered at school, and they lose the freedom to choose for themselves.\\n\\nStudents are quite busy people. They get homework from multiple classes, participate in sports or music classes, and they hangout with their friends and have fun being a teenager. Making students be forced to stay after school would not work for students who play sports and have practice, or students who have to help support their families with a job. Having them be forced to do an activity would take away time from other things that they need to do, or things that they want to do.\\n\\nEveryone has different taste. Some people like to play basketball, some like to play hockey, some like to play football. Likewise, students all have different sets of skills and things that they enjoy. Some students may want to do something that is not offered at that school, yet they wouldn't be able to. It doesn't make sense that they should participate in something that they don't enjoy. If a person who does not like to play sports is forced to play an after school sport, that would unfair towards them. Or, if a person who only likes to draw has to take an extracurricular activity, what would they do if there isn't an art club? Making the students do something they would not like or they're not interested in is not very fair.\\n\\nPeople are free to choose to do what they want, and everyone has that freedom. Making participation mandatory for extracurricular activities is impeding on the students right to choose for themselves. They learn in their classes that everyone has their rights, and taking them away is very unconstitutional, so it's ironic that their ability to have a choice is taken away from them. They don't have the freedom to choose if they want to participate anymore, which is unfair.\\n\\nIf we look on the other side of this argument, the point is that students should take extracurricular activities to better themselves. This actually makes sense, except that they should be required to do it. Mandatory participation in extracurricular activities is bad for students because the students may not have time, they might not be interested and they lose the ability to choose for themselves. It is important students that students have the right to choose so they know that there are always options. If students are forced to take extracurricular activites, they will become more disheartened, more weary and tired from balancing their social and academic lives along with sports and other classes, and wake up with less promise that they would have a good day. After all, we do need to nurture our students, as they are the future of the world, as the next generation.\",\n",
       "  \"Some schools require students to complete summer projects to guarantee that students will continue to learn during their summer break. It is essential that students keep learning even though they are taking a break from school, but these summer projects should be teacher-designed.\\xa0Why should a students not be allowed to choose a project of their liking? Well, the student's teacher will know what that person needs to work on. If a student were to choose what they would like their project to be about, they could probably decide to work on something that does not require much effort; therefore, it would be best if a professional particularly assigned a certain topic to help his or her pupil designated to help them grow and become more efficient in their academic life. However, if the student believes that there is a specific topic they believe they need to practice more than the teacher should consider to make an exemption.\\n\\nStudents would certainly benefit if they were given homework over summer. This action would ensure that the student will be ready to tackle classroom assignments once they are back to school. Not only that but it would also let the student perfect their skills and be prepared in class. These projects designated to students will surely boost the alumni's knowledge and confidence on that specific topic. Therefore, the student will not struggle as much as they would have without the extra help.\\n\\nIn addition, if teachers assign students particular homework designed to help their alumni be more efficient in class, it is undeniable that their student's classroom performance will have a positive effect in their academic life. The teacher ,being a professional, will have more understanding of what their student needs to work on. He or she can personalize the project to better help the student understand and learn about their assignment. The extra help given to the alumni will have positive results and they could use their knowledge acquired by the project on other classes, or these young adults can use this information outside of school to help them handle outside of school life situations. If trained professionals give students homework during summer break, then those students will be able to see how this extra work helped them master skills when school opens again.\\n\\nStudents should not be given the privilege to choose their own project assignments. Some students would pick easy topics that would not require them to put much effort, this will deeply harm the student academically. Instead of working hard to perfect an area in which\\xa0the student struggles, they would rather choose something that is easy and would get done quickly. This is why it is better if teachers gave students their assignments. However, it can not be guaranteed that the students will learn or understand the homework assignment. For that reason could be that maybe the student is not ready to take on that particular topic. Without a doubt, it is known that not all students learn the same way and not all understand what they have learned. Everybody learns at their own pace and in their own way. If the student believes that the designated work is too hard, or maybe too easy, then they should talk to their teacher and suggest\\xa0a different topic. Also, if the students thinks that there is another area they need to practice more, they should ask their teacher to consider their request.\\n\\nSchools that require students to continue learning during the summer will see positive results in students academic lives. Designated work from teachers will greatly help alumni master and perfect classroom skills. Not to mention, students will acquire more knowledge on these areas with the extra help that was provided. If the teacher knows what their students need to work more on, those students will soon be ready to take on anything once school is in cession again. If students were given the liberty to pick their projects, would the students actually learn from it? What happens if the student chooses an easy project, when they could have been working on some other topic that they know they have trouble with? This will certainly not be a good idea. As professionals, teachers know what is best for their students if they have been observing their classroom performance. However, Many teachers sometimes overlook a few things in which student have trouble with. When this happens the student should take a step forward and let their teacher know what it is they think they need to work. This way the teacher can look back and verify is this person does need to practice more in the areas that they may be struggling.\",\n",
       "  'In the 1960\\'s driverless cars seemed more as like a futuristic fantasy rather than reality, but in todays world, they just might be the next big thing. In the late 1950\\'s, General Motors created a concept car that could run on a special test track (Ph. 3). Although this was the first concept of a \"smart car\", the roads would need an unrealistic upgrade that would cost extremely to much. Today however, we have the technology to make real driverless cars. The toll of human error has been evident in the auto-age as more accidents happen every year. The use of driverless cars, or at least almost driverless cars, will be benificial to the future as less accidents will happen, preventing more casualties.\\n\\nToday, many cars all across America and the world have road assistance and antilock breaks, but this still gives drivers the oppurtunity to make a mistake and cause an accident. For example, BMW created a system called \" Traffic Jam Assistant\". The car is capable of handling situations at speeds up to 25 mph. This is not bulletproof though, as the human driver still has to be alert when navigating through construction and accidents. Developers though, are getting closer to having real driverless cars. Tesla has projected a 2016 release for a car capable of driving on autopilot 90% of the time (Ph.10).\\n\\nTechnology today makes creations and inventions capable of almost anything. We have had extreneous experience with sensors and radar, two things that are almost required for a driverless car in the upcoming future, to make one. In the 1980\\'s, more than 30 years ago, automakers used speed sensors at the wheels in the creation of antilock brakes (Ph. 5). With all of the experience gained, we now can make real driverless cars. Infact, we all ready have. Google has had cars that could drive independently under specific conditions since 2009 (Ph. 2). Their cars have driven more than half a million miles without a crash, but roadblocks and problems do lie ahead for a true \"driverless car\".\\n\\nTraffic laws are written with the asssumption that the only safe car has a human driver in contral at all times (Ph. 9). As a result, many states restrict the use of driverless cars on the roads. As driverless cars are a relatively new idea, restrictions will be diminished in due time. Opposers of driverless cars have also made the claim that liability will possibly be the dimise of driverless cars. The discussion of whether or not the human in the seat or the car manufacturer will no doubt be on the minds of lawmakers, but they would quicky come to the conclusion that it would be the driver\\'s fault, since the driver bought the car and knew what he/she was getting into. Manufacturers would also make a liability agreement required in order to driver the car.\\n\\nAlthough driverless cars will not probably be 100% driverless, the creation of almost driverless cars is not far down in world history. The use of driverless cars, or at least almost driverless, will be beneficial to the future as less accidents will happen, preventing more casualties.            '],\n",
       " 'essay_text_UPD': ['Dear Senator\\n\\nThe Electoral College was created by our Founding Fathers. They put this in the Constitution to make electing the President of the United States fair and equal to all the citizens in the United States. The Electoral College should not be changed no matter what. To go against the Constitution would be to go against the nation, for we were built on the leadership of our Founding Fathers and the guidance of the Constitution. This Contitstution was created so that the people have more power than the government. So I strongly believe that the Electoral College should stay the same. It is the governmet that needs to change. There is nothing wrong with the Electoral College, it is just the ones that run it. So if there should be any change, it should be the government that should change, not the Electoral College!\\n\\nThe Ectoral College is a compromise between the election of the President by a vote in Congress and by the popular vote of the citizens. When the voting starts the electors come to a meeting place and vote on who they want as President. After the meeting, there has to be a majority of two hundred seventy electoral votes for the election of the president. The electoral College is as I have said it before is fair and equal to all the citizens in the United States. To take this away now would be a catastraphe, because that would mean that all the other presidents in the past would not have even been our Presidents, the history behind them would be rubish and not even true. Some states may have a \"winner-take-all\" sort of thing but they are together and voting together as on state. Some of them may vote for the other one but the majority of them is for one person. Some of the states believe that it is not even worth it to have a \"winner-take-all\", because they think it is unfair. Then after the presidential election comes the \"Certificate of Ascertainment\" which is a list of all those who ran for President and there respective electors.\\n\\nThe electoral college has been around ever since the Constitution was created. It may be unfair now, but if there would have been any changes to the Constitution it would have been done then instead of now. The Electoral College was probably a great idea when the the Constitution fisrt started out. Then the years have gone by and now we want change. Well I see that the Electoral College can be unfair but it is also fair in it\\'s own right. Because of the fiasco in the year of two thousand about the abolishment of the Electoral College, it has left a scare in our nation about the government, because you guys are giving out the information on the candidates to late or not at all. That SUCKS, for most states because they may not even get one advertisment about the candidates any where or even a commercial on T.V. If the vote for the abolishment of the Electoral College does happen, then there is nothing that I can do about it, but you can still change your ways. You can make it fair and not irrational. Even send the \"Certificate of Ascertainment\" earlier than you have done before now. This is a nation of freedom and peace, how are you trying to keep the peace with other countries if you can not even keep the peace within your own?\\n\\nThe government is the real problem, not the Electoral College. It may be unfair, because the majority of the people may have chosen one person while the electors may choose the other. Then when they add it together it is there vote that counts more than the peoples. If the government had only done the right thing and elected what the people wanted, then no one would have a problem with the Electoral College. It is stupid that the government is listening to what we have to say but not hearing it completly. The Constitution is a document of equality for the people. Not the government. If our nations democracy is a democracy then they should listen more to what the people have to say and not what the government has to say. If the government would do this then things would run more smoothly within our country and there would be less conflict.\\n\\nThis nation is a nation of freedom and peace. Not for a bunch of people who are power hungry. The Electoral College is fair and equal, it is the government that is not. If the government would only change for the better then there would be no problem. This nation is still young compared to all the other countries. They have gotten all there issues taken care of, but we have not. The reason is that some of the officials are power hungry and do things to take care of themselves and not others, but some are not and they want to make this country better. Those are the ones that should stay and not the power hungry ones. They make it fair. So I strongly belive that the Electoral College should stay the same, and that the government should be the one to change.\\n\\nFrome PROPER_NAME',\n",
       "  \"Dear State Senator,\\n\\nI read all these articles about some states having to vote for the president's electors. They say basically when your voting for a president, your voting for his/hers electors. My opinion is there should be no need for electors. It should be easy and not too complicated. A presdient, a vice president, and a secatary. No electors or nothing. I think a president can do alot of his own work and think of ideas alone. If he need help than instead of us wasting our time with voting for people to give the presdient ideas and help him out. Well the President always say's God Bless America. Shouldn't the President be listening to the voices of his country. America. Yes, I think the candidate with the most votes should win. But, If they say that their going to do something for our country than they need to keep their word. Make it a better place not for himslef but for everyone. For instance, Barack Obama. What's the need for this unessarcy work that he has done. America is loosing their mind and doesnt know what's going on. Why is he doing this? The president is to make smart decent relevant choices. And if he listen to the voices of Americans than he would have lots of ideas lots! Instead he listens to who? His electors. People complain saying to themselfs, Where does he come up with these ideas? Well if you payed close attention to the presidents background and know what he really wants to do than you would know why. Honestly to me I dont think the Electoral College should keep going its just a bunch of mess that just doesnt make sence. Elelctors dont matter to most American's. Take the electors and the Electoral College away we dont want something we dont need. All we need is a President, a Vice Presdient, and a Secatary.\\n\\nSencerely, America\",\n",
       "  \"After the school year ends, students return to their homes feeling a great sense of relief that the school year is over, and that they're about to get a much needed break. However, just because school has stopped doesn't mean that learning should. Three entire months off is long time, and many students actually forget most of what they learned over the past year and need to be refreshed when they return to school. It would save everyone a lot of time if students came back to school with the last year's information still fresh in their minds. The simple solution to this problem is summer assignments. However, it is critically important that these summer assignments are student-designed, meaning that most of what is done for the assignment is thought of by the student rather than simply following the guidelines of their teacher. It is necessary that summer work be student-designed because it encourages and teaches self motivated learning, will be something the student is more passionate about, and will be less stress on teachers.\\n\\nThe first benefit of summer work being controlled by students is that it encourages and teaches self-motivated learning. Self-motivated learning is when the student has a desire to learn and therefore works hard to learn information without having to be pushed by their teachers. The truth is that while teachers can relay all the necessary information to students, if the students don't want anything to do with it they will learn far less effectively than students who do want to learn. By asking students to create their own summer assignment, it forces them into a new learning environment in which they have to take charge of their learning. Upon being put into this position, students will have to adapt to learn how to teach themselves information. This is a very valuble life skill that will be very helpful to them later in their lives, as self-education is needed for many things that are not taught in school as well as in the workplace. Motivating themselves is an important skill that can be taught through student-designed summer work.\\n\\nOn a similar note, giving students the ability to choose between what they have to do for their summer projects enables them to make the topic or submission format something that they are more passionate about than what they might otherwise be taught in school. Typically, in a learning context, more passion or excitement transfers to more success at whatever it is the students are trying to learn. Being more passionate about something causes people to interact with it much more, and interaction is key to the learning of many students. In addition, students being excited to do something furthers the self-motivation mentioned above. If there is something that a student wants to do, they will do it without needing a teacher to tell them to. Overall, the passion that comes from student-designed summer work makes it a much more fun and more effective experience for students.\\n\\nTo make things even better, student -designed summer work won't only be helping the students, it will be helping the teachers. Teachers work very hard to plan, produce, and grade all of the students' schoolwork for the entire school year. They deserve to have a break! By letting students take charge of their summer work, it takes an extra burden off the shoulders of the people who dedicated their lives to educating America's youth for a meager government salary. With the extra time they have without having to plan and construct a summer assignment, teachers can do many things, such as get the jump on later assignments that they will have to make, enjoy some time with their friends and family, or just get some much needed sleep. This extra time for teachers is another fantastic reason why summer assignments should be student-designed.\\n\\nThere is no doubt that summer assignments are a necessary part of learning, in order to continue to teach information and to help students remember information that they would otherwise forget. But these assignments should not be simple rubrics and reading notes, they should be something different. Something that is going to have a significant impact on everyone in the education system. Something that will build a strong new generation without overworking the old ones. Those who are students understand the value of enjoying and wanting to learn about a subject, those who are educators know how important it is to be able to motivate yourself to work, and those who are school teachers know that a little extra time and a little less stress goes a very long way. That is why summer assignments should be student designed rather than teacher-designed.\",\n",
       "  'The program Seagoing Cowboys ,is amazing even though u might of heard of it or not im going to try my best to make u want to be part of it. I say this because for example the program lets u go around the world,like in the story the said that Luke had travewled nine diffrent times. Isnt that great that could be you,of course if u would like to join.\\n\\nThere are lots of things that u could do there,like get to meet knew people and some might even become very close to you. I am sure that if you, came to the program you would love it. You would have fun,free food,and a good place to sleep. Now some might lo0ve animals , and if u dont thats fine but im sure you would start to. they are kind,loving,and gental. This program might get u in shapeand fit,you will be caring and lifting things and im sure that will burn off some fat.\\n\\nAlso if u come to the program,u would learn how to obay,clean,and be respectful. Im sure that a young mans mother would be happy to know that,they are cleaning, and obaying laws,and showing respecfulness. Oh and befor i forget, they also will be able to cook multipal meals for his family.\\n\\nThe lastly they will be cowboys,and thats a great thing to help out with the animals. The young men will be helping around with horses,and cows. I am sure that the young man, will enjoy the view of the world that hes traviling.\\n\\nI hope that you are convinced and made up your mind to let the young men come to this program. I am sure that youll enjoy it, till next time .',\n",
       "  'The use of this advanced technology to read the emotional expressions of students in a classroom is valuable from three reasons in the article that the author tells us by reading this article.\\n\\nIt\\'s interesting to think ahead and create something big that no one can do. In paragraph 3, the author says, \"The process begins when the computer constructs a 3-D computer model of the face; all 44 major muscles in the model must move like human muscles.\" The 44 muscles can tell how the human is feeling, by seeing how the person is moving. For example, when the person is moving really fast, it means that the person might be angry or aggressive. But when a person is moving slow, it means that the person is sad or depressed.\\n\\nThe author tells in the text, \"We humans perform this same impressive calculation every day.\" But comparing a human mind to a computer is different. A human mind can think that the friend is feeling sad, but the computer can have more than just one idea of how the friend feels. The computer can have more than one idea by scanning the face of the person and calculating how the muscles of the face look. It may seem amazing to try to use the technology.\\n\\nFrom the picture of Mona Lisa, when you just look at it, many ideas would pop up in your head from trying to guess how she\\'s feeling and how she looks. There would be multiple guesses on how her face looks. In paragraph 6, the author says, \"The Mona Lisa demonstration is really intended to bring a smile to your face, while it shows just how much this computer can do.\" Some people might say that she looks mostly happy, a bit disgusted, somewhat fearful, and a little angry. Or they might say all of them and more. We all have different minds, different thoughts, and a different sights at describing a picture.\\n\\nMoreover, the article gives us a lot of information of the advanced technological computer that constructs a 3-D model, to scan a human face and tell how the person feels emotionally. It\\'s amazing and interesting to even read about Dr. Huang and Prof. Sebe ,his colleague, are both experts at developing better ways for humans and computers to communicate.',\n",
       "  \"It may be true that some of us do abuse the fact that we are allowed cell phones at school. However, many of us respect our teachers and leave our phones turned off, only using them when permitted.\\n\\nIt would be a horrible and unfair thing to do for the school to take our phone privileges away. Many students may use them during class when they are supposed to be paying attention to their teachers, but not all students. Phones are a fun way to talk to our friends and family, even if they shouldn't be used during class.\\n\\nPhones are also great for emergencies, whether it's to call your parents about a school bus running late or if it's calling the police for a wanted criminal taking you hostage at the school. For this reason, new school policies could just be effecting the safety of the students. Many of us love our phones and would hate for our rights to be completely taken away.\\n\\nIn addition, some students need their phones. Protective parents may require their children to call or text them during break time to let them know they're doing okay.\\n\\nCell phones are a great source for entertainment as well as a social device. Some people can put music or games on their phones to listen to or play during the day. Anti-social students may like using this during break time and lunch time to entertain themselves.\\n\\nWhat harm would it do to allow students to use their phones during their lunch and break times? Class wouldn't be disrupted, teachers wouldn't be annoyed, and the students would still be able to have the phones that they enjoy using every day. By changing the phone policy, the school would be taking our rights away. This is also very unfair to those who use their phones outside of class. If we can't be trusted with phones only during our break times, then the school would be showing us great disrespect.\",\n",
       "  'Dear Senator,\\n\\nGood day, I am writing this letter to let you know it\\'s time for things to change. I have been reading and researching the Electoral College and i have a strong opinion on it. As you know, the Electoral College is a process when all five hundred and thirty eight electors vote on electors and defenders. This way of voting for electors lets the people have no say in whose running our goverment! Our goverment should not allow or be based on \"the winner takes all\" method. When we choose for OUR president we should be able to choose OUR electors too! Under the 23rd amendment of the constitution, the District of Columbia is allocated 3 electors and treated like a state for purposes of the electoral college. The electors shouldnt be chosen by the canidate\\'s political party, we should choose. By voting for a president every four years a new party of electors have already been selected to run with him and we dont get any say. After the presidential election, your governer creates a list of all the canidates that ran for president in your state with a list of their representative electors. This is later sent to Congress and the National Archives as part of the official records of the presidential election.\\n\\nRichard Nixon, Bob Dole, Jimmy Carter, the U.S. Chamber of Commerce, and the AFL-CIO all agree that we need to remove and forget about the electoral college. This year our voters can expect another close election in which the popular vote winner could lose the presidency. Still the electoral college still has defenders fror themselves is crazy. Facts say voters arent actually voting for the president, but for a group of electors who in turn elect the president, and that is ridiculous. How are we supposed to trust these electors if we dont even know who they are and their background until after the election? Who even are these electors i wondered. I figured out that all the electors are actually anyone with a brain and not holding a public office, fantastic. So how do i know they are reliable and going to do whats best for my state and our country? Voters dont even control whom their electors vote for most of the time which is kind of scary. Some electors are even faithless in their party\\'s canidate so they dont even vote for them at all! How can we rely on a group of people who dont rely on their party?\\n\\nAs much as I hate to say it, there most definitley is an upside to the Electoral College. The Electoral College is widely regarded as an anachronism, a non-democratic method of selecting a president that needs to be overruled by declaring the canidate who receives the most popular votes the winner. I personally think that is the best way to decide who gets in. Each party selects a slate of electors that are trusted to vote for the party\\'s nominee. Sometimes the electoral vote will not win the national popular vote. Another reason The Electoral College is a positive way of voting is how certain the outcome is. There is never failure in the counting of the votes and there us rarely a tie between two people. My favorite reason is because \"everybody is president\". This means everybody can make their own decisions and have a great amount of freedom.\\n\\nEven though im all for removing the Electoral College there is positives too. In a few years when i am able to vote, i will be careful of who I vote for and make sure that there is great electors in the party i vote for.',\n",
       "  \"Extracurricular activities are fun. We can play sports after school, join different clubs, or play some games with other students. But we always get to choose what we want to do, right?\\n\\nMandatory participation in extracurricular activities is not good for students because they may not have time to stay after (jobs, other classes, homework, sports) , they might not be interested in any of the activities offered at school, and they lose the freedom to choose for themselves.\\n\\nStudents are quite busy people. They get homework from multiple classes, participate in sports or music classes, and they hangout with their friends and have fun being a teenager. Making students be forced to stay after school would not work for students who play sports and have practice, or students who have to help support their families with a job. Having them be forced to do an activity would take away time from other things that they need to do, or things that they want to do.\\n\\nEveryone has different taste. Some people like to play basketball, some like to play hockey, some like to play football. Likewise, students all have different sets of skills and things that they enjoy. Some students may want to do something that is not offered at that school, yet they wouldn't be able to. It doesn't make sense that they should participate in something that they don't enjoy. If a person who does not like to play sports is forced to play an after school sport, that would unfair towards them. Or, if a person who only likes to draw has to take an extracurricular activity, what would they do if there isn't an art club? Making the students do something they would not like or they're not interested in is not very fair.\\n\\nPeople are free to choose to do what they want, and everyone has that freedom. Making participation mandatory for extracurricular activities is impeding on the students right to choose for themselves. They learn in their classes that everyone has their rights, and taking them away is very unconstitutional, so it's ironic that their ability to have a choice is taken away from them. They don't have the freedom to choose if they want to participate anymore, which is unfair.\\n\\nIf we look on the other side of this argument, the point is that students should take extracurricular activities to better themselves. This actually makes sense, except that they should be required to do it. Mandatory participation in extracurricular activities is bad for students because the students may not have time, they might not be interested and they lose the ability to choose for themselves. It is important students that students have the right to choose so they know that there are always options. If students are forced to take extracurricular activites, they will become more disheartened, more weary and tired from balancing their social and academic lives along with sports and other classes, and wake up with less promise that they would have a good day. After all, we do need to nurture our students, as they are the future of the world, as the next generation.\",\n",
       "  \"Some schools require students to complete summer projects to guarantee that students will continue to learn during their summer break. It is essential that students keep learning even though they are taking a break from school, but these summer projects should be teacher-designed. Why should a students not be allowed to choose a project of their liking? Well, the student's teacher will know what that person needs to work on. If a student were to choose what they would like their project to be about, they could probably decide to work on something that does not require much effort; therefore, it would be best if a professional particularly assigned a certain topic to help his or her pupil designated to help them grow and become more efficient in their academic life. However, if the student believes that there is a specific topic they believe they need to practice more than the teacher should consider to make an exemption.\\n\\nStudents would certainly benefit if they were given homework over summer. This action would ensure that the student will be ready to tackle classroom assignments once they are back to school. Not only that but it would also let the student perfect their skills and be prepared in class. These projects designated to students will surely boost the alumni's knowledge and confidence on that specific topic. Therefore, the student will not struggle as much as they would have without the extra help.\\n\\nIn addition, if teachers assign students particular homework designed to help their alumni be more efficient in class, it is undeniable that their student's classroom performance will have a positive effect in their academic life. The teacher ,being a professional, will have more understanding of what their student needs to work on. He or she can personalize the project to better help the student understand and learn about their assignment. The extra help given to the alumni will have positive results and they could use their knowledge acquired by the project on other classes, or these young adults can use this information outside of school to help them handle outside of school life situations. If trained professionals give students homework during summer break, then those students will be able to see how this extra work helped them master skills when school opens again.\\n\\nStudents should not be given the privilege to choose their own project assignments. Some students would pick easy topics that would not require them to put much effort, this will deeply harm the student academically. Instead of working hard to perfect an area in which the student struggles, they would rather choose something that is easy and would get done quickly. This is why it is better if teachers gave students their assignments. However, it can not be guaranteed that the students will learn or understand the homework assignment. For that reason could be that maybe the student is not ready to take on that particular topic. Without a doubt, it is known that not all students learn the same way and not all understand what they have learned. Everybody learns at their own pace and in their own way. If the student believes that the designated work is too hard, or maybe too easy, then they should talk to their teacher and suggest a different topic. Also, if the students thinks that there is another area they need to practice more, they should ask their teacher to consider their request.\\n\\nSchools that require students to continue learning during the summer will see positive results in students academic lives. Designated work from teachers will greatly help alumni master and perfect classroom skills. Not to mention, students will acquire more knowledge on these areas with the extra help that was provided. If the teacher knows what their students need to work more on, those students will soon be ready to take on anything once school is in cession again. If students were given the liberty to pick their projects, would the students actually learn from it? What happens if the student chooses an easy project, when they could have been working on some other topic that they know they have trouble with? This will certainly not be a good idea. As professionals, teachers know what is best for their students if they have been observing their classroom performance. However, Many teachers sometimes overlook a few things in which student have trouble with. When this happens the student should take a step forward and let their teacher know what it is they think they need to work. This way the teacher can look back and verify is this person does need to practice more in the areas that they may be struggling.\",\n",
       "  'In the 1960\\'s driverless cars seemed more as like a futuristic fantasy rather than reality, but in todays world, they just might be the next big thing. In the late 1950\\'s, General Motors created a concept car that could run on a special test track (Ph. 3). Although this was the first concept of a \"smart car\", the roads would need an unrealistic upgrade that would cost extremely to much. Today however, we have the technology to make real driverless cars. The toll of human error has been evident in the auto-age as more accidents happen every year. The use of driverless cars, or at least almost driverless cars, will be benificial to the future as less accidents will happen, preventing more casualties.\\n\\nToday, many cars all across America and the world have road assistance and antilock breaks, but this still gives drivers the oppurtunity to make a mistake and cause an accident. For example, BMW created a system called \" Traffic Jam Assistant\". The car is capable of handling situations at speeds up to 25 mph. This is not bulletproof though, as the human driver still has to be alert when navigating through construction and accidents. Developers though, are getting closer to having real driverless cars. Tesla has projected a 2016 release for a car capable of driving on autopilot 90% of the time (Ph.10).\\n\\nTechnology today makes creations and inventions capable of almost anything. We have had extreneous experience with sensors and radar, two things that are almost required for a driverless car in the upcoming future, to make one. In the 1980\\'s, more than 30 years ago, automakers used speed sensors at the wheels in the creation of antilock brakes (Ph. 5). With all of the experience gained, we now can make real driverless cars. Infact, we all ready have. Google has had cars that could drive independently under specific conditions since 2009 (Ph. 2). Their cars have driven more than half a million miles without a crash, but roadblocks and problems do lie ahead for a true \"driverless car\".\\n\\nTraffic laws are written with the asssumption that the only safe car has a human driver in contral at all times (Ph. 9). As a result, many states restrict the use of driverless cars on the roads. As driverless cars are a relatively new idea, restrictions will be diminished in due time. Opposers of driverless cars have also made the claim that liability will possibly be the dimise of driverless cars. The discussion of whether or not the human in the seat or the car manufacturer will no doubt be on the minds of lawmakers, but they would quicky come to the conclusion that it would be the driver\\'s fault, since the driver bought the car and knew what he/she was getting into. Manufacturers would also make a liability agreement required in order to driver the car.\\n\\nAlthough driverless cars will not probably be 100% driverless, the creation of almost driverless cars is not far down in world history. The use of driverless cars, or at least almost driverless, will be beneficial to the future as less accidents will happen, preventing more casualties.'],\n",
       " 'labels': [1, 1, 2, 1, 1, 1, 1, 2, 1, 1],\n",
       " '__index_level_0__': [26925,\n",
       "  27530,\n",
       "  9622,\n",
       "  8283,\n",
       "  5727,\n",
       "  25187,\n",
       "  31054,\n",
       "  6714,\n",
       "  14067,\n",
       "  20991],\n",
       " 'input_ids': [[101,\n",
       "   1996,\n",
       "   6092,\n",
       "   2267,\n",
       "   2003,\n",
       "   2004,\n",
       "   1045,\n",
       "   2031,\n",
       "   2056,\n",
       "   2009,\n",
       "   2077,\n",
       "   2003,\n",
       "   4189,\n",
       "   1998,\n",
       "   5020,\n",
       "   2000,\n",
       "   2035,\n",
       "   1996,\n",
       "   4480,\n",
       "   1999,\n",
       "   1996,\n",
       "   2142,\n",
       "   2163,\n",
       "   1012,\n",
       "   2000,\n",
       "   2202,\n",
       "   2023,\n",
       "   2185,\n",
       "   2085,\n",
       "   2052,\n",
       "   2022,\n",
       "   1037,\n",
       "   4937,\n",
       "   14083,\n",
       "   24342,\n",
       "   2063,\n",
       "   1010,\n",
       "   102],\n",
       "  [101,\n",
       "   2748,\n",
       "   1010,\n",
       "   1045,\n",
       "   2228,\n",
       "   1996,\n",
       "   4018,\n",
       "   2007,\n",
       "   1996,\n",
       "   2087,\n",
       "   4494,\n",
       "   2323,\n",
       "   2663,\n",
       "   102],\n",
       "  [101,\n",
       "   2044,\n",
       "   1996,\n",
       "   2082,\n",
       "   2095,\n",
       "   4515,\n",
       "   1010,\n",
       "   2493,\n",
       "   2709,\n",
       "   2000,\n",
       "   2037,\n",
       "   5014,\n",
       "   3110,\n",
       "   1037,\n",
       "   2307,\n",
       "   3168,\n",
       "   1997,\n",
       "   4335,\n",
       "   2008,\n",
       "   1996,\n",
       "   2082,\n",
       "   2095,\n",
       "   2003,\n",
       "   2058,\n",
       "   1010,\n",
       "   1998,\n",
       "   2008,\n",
       "   2027,\n",
       "   1005,\n",
       "   2128,\n",
       "   2055,\n",
       "   2000,\n",
       "   2131,\n",
       "   1037,\n",
       "   2172,\n",
       "   2734,\n",
       "   3338,\n",
       "   1012,\n",
       "   2174,\n",
       "   1010,\n",
       "   2074,\n",
       "   2138,\n",
       "   2082,\n",
       "   2038,\n",
       "   3030,\n",
       "   2987,\n",
       "   1005,\n",
       "   1056,\n",
       "   2812,\n",
       "   2008,\n",
       "   4083,\n",
       "   2323,\n",
       "   1012,\n",
       "   2093,\n",
       "   2972,\n",
       "   2706,\n",
       "   2125,\n",
       "   2003,\n",
       "   2146,\n",
       "   2051,\n",
       "   1010,\n",
       "   1998,\n",
       "   2116,\n",
       "   2493,\n",
       "   2941,\n",
       "   5293,\n",
       "   2087,\n",
       "   1997,\n",
       "   2054,\n",
       "   2027,\n",
       "   4342,\n",
       "   2058,\n",
       "   1996,\n",
       "   2627,\n",
       "   2095,\n",
       "   1998,\n",
       "   2342,\n",
       "   2000,\n",
       "   2022,\n",
       "   25416,\n",
       "   21898,\n",
       "   2098,\n",
       "   2043,\n",
       "   2027,\n",
       "   2709,\n",
       "   2000,\n",
       "   2082,\n",
       "   1012,\n",
       "   2009,\n",
       "   2052,\n",
       "   3828,\n",
       "   3071,\n",
       "   1037,\n",
       "   2843,\n",
       "   1997,\n",
       "   2051,\n",
       "   2065,\n",
       "   2493,\n",
       "   2234,\n",
       "   2067,\n",
       "   2000,\n",
       "   2082,\n",
       "   2007,\n",
       "   1996,\n",
       "   2197,\n",
       "   2095,\n",
       "   1005,\n",
       "   1055,\n",
       "   2592,\n",
       "   2145,\n",
       "   4840,\n",
       "   1999,\n",
       "   2037,\n",
       "   9273,\n",
       "   1012,\n",
       "   1996,\n",
       "   3722,\n",
       "   5576,\n",
       "   2000,\n",
       "   2023,\n",
       "   3291,\n",
       "   2003,\n",
       "   2621,\n",
       "   14799,\n",
       "   1012,\n",
       "   102],\n",
       "  [101,\n",
       "   2066,\n",
       "   2131,\n",
       "   2000,\n",
       "   3113,\n",
       "   2354,\n",
       "   2111,\n",
       "   1998,\n",
       "   2070,\n",
       "   2453,\n",
       "   2130,\n",
       "   2468,\n",
       "   2200,\n",
       "   2485,\n",
       "   2000,\n",
       "   2017,\n",
       "   1012,\n",
       "   1045,\n",
       "   2572,\n",
       "   2469,\n",
       "   2008,\n",
       "   2065,\n",
       "   2017,\n",
       "   1010,\n",
       "   2234,\n",
       "   2000,\n",
       "   1996,\n",
       "   2565,\n",
       "   2017,\n",
       "   2052,\n",
       "   2293,\n",
       "   2009,\n",
       "   1012,\n",
       "   2017,\n",
       "   2052,\n",
       "   2031,\n",
       "   4569,\n",
       "   1010,\n",
       "   2489,\n",
       "   2833,\n",
       "   1010,\n",
       "   1998,\n",
       "   1037,\n",
       "   2204,\n",
       "   2173,\n",
       "   2000,\n",
       "   3637,\n",
       "   1012,\n",
       "   2085,\n",
       "   2070,\n",
       "   2453,\n",
       "   8840,\n",
       "   2692,\n",
       "   3726,\n",
       "   4176,\n",
       "   1010,\n",
       "   1998,\n",
       "   2065,\n",
       "   1057,\n",
       "   2123,\n",
       "   2102,\n",
       "   2008,\n",
       "   2015,\n",
       "   2986,\n",
       "   2021,\n",
       "   10047,\n",
       "   2469,\n",
       "   2017,\n",
       "   2052,\n",
       "   2707,\n",
       "   2000,\n",
       "   1012,\n",
       "   2027,\n",
       "   2024,\n",
       "   2785,\n",
       "   1010,\n",
       "   8295,\n",
       "   1010,\n",
       "   1998,\n",
       "   8991,\n",
       "   9080,\n",
       "   1012,\n",
       "   2023,\n",
       "   2565,\n",
       "   2453,\n",
       "   2131,\n",
       "   1057,\n",
       "   1999,\n",
       "   4338,\n",
       "   5685,\n",
       "   4906,\n",
       "   1010,\n",
       "   2017,\n",
       "   2097,\n",
       "   2022,\n",
       "   11922,\n",
       "   1998,\n",
       "   8783,\n",
       "   2477,\n",
       "   1998,\n",
       "   10047,\n",
       "   2469,\n",
       "   2008,\n",
       "   2097,\n",
       "   6402,\n",
       "   2125,\n",
       "   2070,\n",
       "   6638,\n",
       "   1012,\n",
       "   102],\n",
       "  [101,\n",
       "   1996,\n",
       "   3166,\n",
       "   4136,\n",
       "   1999,\n",
       "   1996,\n",
       "   3793,\n",
       "   1010,\n",
       "   1000,\n",
       "   2057,\n",
       "   4286,\n",
       "   4685,\n",
       "   2023,\n",
       "   2168,\n",
       "   8052,\n",
       "   17208,\n",
       "   2296,\n",
       "   2154,\n",
       "   1012,\n",
       "   1000,\n",
       "   2021,\n",
       "   13599,\n",
       "   1037,\n",
       "   2529,\n",
       "   2568,\n",
       "   2000,\n",
       "   1037,\n",
       "   3274,\n",
       "   2003,\n",
       "   2367,\n",
       "   1012,\n",
       "   1037,\n",
       "   2529,\n",
       "   2568,\n",
       "   2064,\n",
       "   2228,\n",
       "   2008,\n",
       "   1996,\n",
       "   2767,\n",
       "   2003,\n",
       "   3110,\n",
       "   6517,\n",
       "   1010,\n",
       "   2021,\n",
       "   1996,\n",
       "   3274,\n",
       "   2064,\n",
       "   2031,\n",
       "   2062,\n",
       "   2084,\n",
       "   2074,\n",
       "   2028,\n",
       "   2801,\n",
       "   1997,\n",
       "   2129,\n",
       "   1996,\n",
       "   2767,\n",
       "   5683,\n",
       "   1012,\n",
       "   1996,\n",
       "   3274,\n",
       "   2064,\n",
       "   2031,\n",
       "   2062,\n",
       "   2084,\n",
       "   2028,\n",
       "   2801,\n",
       "   2011,\n",
       "   13722,\n",
       "   1996,\n",
       "   2227,\n",
       "   1997,\n",
       "   1996,\n",
       "   2711,\n",
       "   1998,\n",
       "   20177,\n",
       "   2129,\n",
       "   1996,\n",
       "   6650,\n",
       "   1997,\n",
       "   1996,\n",
       "   2227,\n",
       "   2298,\n",
       "   102],\n",
       "  [101,\n",
       "   3526,\n",
       "   11640,\n",
       "   2024,\n",
       "   1037,\n",
       "   2307,\n",
       "   3120,\n",
       "   2005,\n",
       "   4024,\n",
       "   2004,\n",
       "   2092,\n",
       "   2004,\n",
       "   1037,\n",
       "   2591,\n",
       "   5080,\n",
       "   102],\n",
       "  [101,\n",
       "   2004,\n",
       "   2172,\n",
       "   2004,\n",
       "   1045,\n",
       "   5223,\n",
       "   2000,\n",
       "   2360,\n",
       "   2009,\n",
       "   1010,\n",
       "   2045,\n",
       "   2087,\n",
       "   13366,\n",
       "   5498,\n",
       "   18492,\n",
       "   2003,\n",
       "   2019,\n",
       "   14961,\n",
       "   2000,\n",
       "   1996,\n",
       "   6092,\n",
       "   2267,\n",
       "   1012,\n",
       "   102],\n",
       "  [101,\n",
       "   10915,\n",
       "   6577,\n",
       "   1999,\n",
       "   4469,\n",
       "   10841,\n",
       "   21231,\n",
       "   3450,\n",
       "   2003,\n",
       "   2919,\n",
       "   2005,\n",
       "   2493,\n",
       "   2138,\n",
       "   1996,\n",
       "   2493,\n",
       "   2089,\n",
       "   2025,\n",
       "   2031,\n",
       "   2051,\n",
       "   1010,\n",
       "   2027,\n",
       "   2453,\n",
       "   2025,\n",
       "   2022,\n",
       "   4699,\n",
       "   1998,\n",
       "   2027,\n",
       "   4558,\n",
       "   1996,\n",
       "   3754,\n",
       "   2000,\n",
       "   5454,\n",
       "   2005,\n",
       "   3209,\n",
       "   1012,\n",
       "   2009,\n",
       "   2003,\n",
       "   2590,\n",
       "   2493,\n",
       "   2008,\n",
       "   2493,\n",
       "   2031,\n",
       "   1996,\n",
       "   2157,\n",
       "   2000,\n",
       "   5454,\n",
       "   2061,\n",
       "   2027,\n",
       "   2113,\n",
       "   2008,\n",
       "   2045,\n",
       "   2024,\n",
       "   2467,\n",
       "   7047,\n",
       "   1012,\n",
       "   2065,\n",
       "   2493,\n",
       "   2024,\n",
       "   3140,\n",
       "   2000,\n",
       "   2202,\n",
       "   4469,\n",
       "   10841,\n",
       "   21231,\n",
       "   2552,\n",
       "   12848,\n",
       "   7616,\n",
       "   1010,\n",
       "   2027,\n",
       "   2097,\n",
       "   2468,\n",
       "   2062,\n",
       "   9841,\n",
       "   14644,\n",
       "   6528,\n",
       "   2098,\n",
       "   1010,\n",
       "   2062,\n",
       "   16040,\n",
       "   1998,\n",
       "   5458,\n",
       "   2013,\n",
       "   20120,\n",
       "   2037,\n",
       "   2591,\n",
       "   1998,\n",
       "   3834,\n",
       "   3268,\n",
       "   2247,\n",
       "   2007,\n",
       "   2998,\n",
       "   1998,\n",
       "   2060,\n",
       "   4280,\n",
       "   1010,\n",
       "   1998,\n",
       "   5256,\n",
       "   2039,\n",
       "   2007,\n",
       "   2625,\n",
       "   4872,\n",
       "   2008,\n",
       "   2027,\n",
       "   2052,\n",
       "   2031,\n",
       "   1037,\n",
       "   2204,\n",
       "   2154,\n",
       "   1012,\n",
       "   2044,\n",
       "   2035,\n",
       "   1010,\n",
       "   2057,\n",
       "   2079,\n",
       "   2342,\n",
       "   2000,\n",
       "   27617,\n",
       "   11244,\n",
       "   2256,\n",
       "   2493,\n",
       "   1010,\n",
       "   2004,\n",
       "   2027,\n",
       "   2024,\n",
       "   1996,\n",
       "   2925,\n",
       "   1997,\n",
       "   1996,\n",
       "   2088,\n",
       "   1010,\n",
       "   2004,\n",
       "   1996,\n",
       "   2279,\n",
       "   4245,\n",
       "   1012,\n",
       "   102],\n",
       "  [101,\n",
       "   1996,\n",
       "   3076,\n",
       "   1005,\n",
       "   1055,\n",
       "   3836,\n",
       "   2097,\n",
       "   2113,\n",
       "   2054,\n",
       "   2008,\n",
       "   2711,\n",
       "   3791,\n",
       "   2000,\n",
       "   2147,\n",
       "   2006,\n",
       "   1012,\n",
       "   102],\n",
       "  [101,\n",
       "   4026,\n",
       "   4277,\n",
       "   2024,\n",
       "   2517,\n",
       "   2007,\n",
       "   1996,\n",
       "   4632,\n",
       "   17421,\n",
       "   16790,\n",
       "   2008,\n",
       "   1996,\n",
       "   2069,\n",
       "   3647,\n",
       "   2482,\n",
       "   2038,\n",
       "   1037,\n",
       "   2529,\n",
       "   4062,\n",
       "   1999,\n",
       "   24528,\n",
       "   2140,\n",
       "   2012,\n",
       "   2035,\n",
       "   2335,\n",
       "   1006,\n",
       "   6887,\n",
       "   1012,\n",
       "   1023,\n",
       "   1007,\n",
       "   1012,\n",
       "   2004,\n",
       "   1037,\n",
       "   2765,\n",
       "   1010,\n",
       "   2116,\n",
       "   2163,\n",
       "   21573,\n",
       "   1996,\n",
       "   2224,\n",
       "   1997,\n",
       "   4062,\n",
       "   3238,\n",
       "   3765,\n",
       "   2006,\n",
       "   1996,\n",
       "   4925,\n",
       "   1012,\n",
       "   102]],\n",
       " 'attention_mask': [[1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "  [1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1]]}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[\"train\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "9066ebb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: discourse_effectiveness, __index_level_0__, essay_text, discourse_text_UPD, essay_text_UPD, essay_id, discourse_type, discourse_text, discourse_id. If discourse_effectiveness, __index_level_0__, essay_text, discourse_text_UPD, essay_text_UPD, essay_id, discourse_type, discourse_text, discourse_id are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "/home/rohan/.local/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 80\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 03:27, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=200, training_loss=0.7310938262939453, metrics={'train_runtime': 211.5852, 'train_samples_per_second': 1.89, 'train_steps_per_second': 0.945, 'total_flos': 7294116216384.0, 'train_loss': 0.7310938262939453, 'epoch': 5.0})"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "9852c4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../model/sample_distilbert_base\n",
      "Configuration saved in ../model/sample_distilbert_base/config.json\n",
      "Model weights saved in ../model/sample_distilbert_base/pytorch_model.bin\n",
      "tokenizer config file saved in ../model/sample_distilbert_base/tokenizer_config.json\n",
      "Special tokens file saved in ../model/sample_distilbert_base/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model('../model/sample_distilbert_base')\n",
    "# trainer.save_model('../model/sample_gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "967d27d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50256"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d1c170b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2808dea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50256"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc3d3eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SPECIAL_TOKENS_ATTRIBUTES',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_add_tokens',\n",
       " '_additional_special_tokens',\n",
       " '_auto_class',\n",
       " '_batch_encode_plus',\n",
       " '_batch_prepare_for_model',\n",
       " '_bos_token',\n",
       " '_build_conversation_input_ids',\n",
       " '_cls_token',\n",
       " '_convert_id_to_token',\n",
       " '_convert_token_to_id',\n",
       " '_convert_token_to_id_with_added_voc',\n",
       " '_create_or_get_repo',\n",
       " '_create_trie',\n",
       " '_decode',\n",
       " '_decode_use_source_tokenizer',\n",
       " '_encode_plus',\n",
       " '_eos_token',\n",
       " '_eventual_warn_about_too_long_sequence',\n",
       " '_eventually_correct_t5_max_length',\n",
       " '_from_pretrained',\n",
       " '_get_padding_truncation_strategies',\n",
       " '_get_repo_url_from_name',\n",
       " '_mask_token',\n",
       " '_pad',\n",
       " '_pad_token',\n",
       " '_pad_token_type_id',\n",
       " '_processor_class',\n",
       " '_push_to_hub',\n",
       " '_save_pretrained',\n",
       " '_sep_token',\n",
       " '_set_processor_class',\n",
       " '_tokenize',\n",
       " '_unk_token',\n",
       " 'add_bos_token',\n",
       " 'add_prefix_space',\n",
       " 'add_special_tokens',\n",
       " 'add_tokens',\n",
       " 'added_tokens_decoder',\n",
       " 'added_tokens_encoder',\n",
       " 'additional_special_tokens',\n",
       " 'additional_special_tokens_ids',\n",
       " 'all_special_ids',\n",
       " 'all_special_tokens',\n",
       " 'all_special_tokens_extended',\n",
       " 'as_target_tokenizer',\n",
       " 'batch_decode',\n",
       " 'batch_encode_plus',\n",
       " 'bos_token',\n",
       " 'bos_token_id',\n",
       " 'bpe',\n",
       " 'bpe_ranks',\n",
       " 'build_inputs_with_special_tokens',\n",
       " 'byte_decoder',\n",
       " 'byte_encoder',\n",
       " 'cache',\n",
       " 'clean_up_tokenization',\n",
       " 'cls_token',\n",
       " 'cls_token_id',\n",
       " 'convert_ids_to_tokens',\n",
       " 'convert_tokens_to_ids',\n",
       " 'convert_tokens_to_string',\n",
       " 'create_token_type_ids_from_sequences',\n",
       " 'decode',\n",
       " 'decoder',\n",
       " 'deprecation_warnings',\n",
       " 'encode',\n",
       " 'encode_plus',\n",
       " 'encoder',\n",
       " 'eos_token',\n",
       " 'eos_token_id',\n",
       " 'errors',\n",
       " 'from_pretrained',\n",
       " 'get_added_vocab',\n",
       " 'get_special_tokens_mask',\n",
       " 'get_vocab',\n",
       " 'init_inputs',\n",
       " 'init_kwargs',\n",
       " 'is_fast',\n",
       " 'mask_token',\n",
       " 'mask_token_id',\n",
       " 'max_len_sentences_pair',\n",
       " 'max_len_single_sentence',\n",
       " 'max_model_input_sizes',\n",
       " 'model_input_names',\n",
       " 'model_max_length',\n",
       " 'name_or_path',\n",
       " 'num_special_tokens_to_add',\n",
       " 'pad',\n",
       " 'pad_token',\n",
       " 'pad_token_id',\n",
       " 'pad_token_type_id',\n",
       " 'padding_side',\n",
       " 'pat',\n",
       " 'prepare_for_model',\n",
       " 'prepare_for_tokenization',\n",
       " 'prepare_seq2seq_batch',\n",
       " 'pretrained_init_configuration',\n",
       " 'pretrained_vocab_files_map',\n",
       " 'push_to_hub',\n",
       " 'register_for_auto_class',\n",
       " 'sanitize_special_tokens',\n",
       " 'save_pretrained',\n",
       " 'save_vocabulary',\n",
       " 'sep_token',\n",
       " 'sep_token_id',\n",
       " 'slow_tokenizer_class',\n",
       " 'special_tokens_map',\n",
       " 'special_tokens_map_extended',\n",
       " 'tokenize',\n",
       " 'tokens_trie',\n",
       " 'truncate_sequences',\n",
       " 'truncation_side',\n",
       " 'unique_no_split_tokens',\n",
       " 'unk_token',\n",
       " 'unk_token_id',\n",
       " 'verbose',\n",
       " 'vocab_files_names',\n",
       " 'vocab_size']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfc5cbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.sep_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0433c35",
   "metadata": {},
   "source": [
    "### PyTorch Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9bb0cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['discourse_id', 'essay_id', 'discourse_text', 'discourse_type', 'discourse_effectiveness', 'discourse_text_UPD', 'essay_text', 'essay_text_UPD', 'labels'],\n",
       "    num_rows: 36765\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "001bef38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['discourse_id', 'essay_id', 'discourse_text', 'discourse_type', 'discourse_effectiveness', 'discourse_text_UPD', 'essay_text', 'essay_text_UPD', 'labels', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 36765\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "853631a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Taken from huggingface lib\n",
    "\n",
    "class DataCollatorWithPadding:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs received.\n",
    "    Args:\n",
    "        tokenizer ([`PreTrainedTokenizer`] or [`PreTrainedTokenizerFast`]):\n",
    "            The tokenizer used for encoding the data.\n",
    "        padding (`bool`, `str` or [`~utils.PaddingStrategy`], *optional*, defaults to `True`):\n",
    "            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n",
    "            among:\n",
    "            - `True` or `'longest'` (default): Pad to the longest sequence in the batch (or no padding if only a single\n",
    "              sequence is provided).\n",
    "            - `'max_length'`: Pad to a maximum length specified with the argument `max_length` or to the maximum\n",
    "              acceptable input length for the model if that argument is not provided.\n",
    "            - `False` or `'do_not_pad'`: No padding (i.e., can output a batch with sequences of different lengths).\n",
    "        max_length (`int`, *optional*):\n",
    "            Maximum length of the returned list and optionally padding length (see above).\n",
    "        pad_to_multiple_of (`int`, *optional*):\n",
    "            If set will pad the sequence to a multiple of the provided value.\n",
    "            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n",
    "            7.5 (Volta).\n",
    "        return_tensors (`str`):\n",
    "            The type of Tensor to return. Allowable values are \"np\", \"pt\" and \"tf\".\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, tokenizer, padding=True, max_length=None, pad_to_multiple_of=None, return_tensors='pt'):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.padding = padding\n",
    "        self.max_length = max_length\n",
    "        self.pad_to_multiple_of = pad_to_multiple_of\n",
    "        self.return_tensors = return_tensors\n",
    "\n",
    "    def __call__(self, features):\n",
    "        batch = self.tokenizer.pad(\n",
    "            features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=self.return_tensors,\n",
    "        )\n",
    "        if \"label\" in batch:\n",
    "            batch[\"labels\"] = batch[\"label\"]\n",
    "            del batch[\"label\"]\n",
    "        if \"label_ids\" in batch:\n",
    "            batch[\"labels\"] = batch[\"label_ids\"]\n",
    "            del batch[\"label_ids\"]\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "49f15549",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:707\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor(value):\n\u001b[0;32m--> 707\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;66;03m# Removing this for now in favor of controlling the shape with `prepend_batch_axis`\u001b[39;00m\n\u001b[1;32m    710\u001b[0m     \u001b[38;5;66;03m# # at-least2d\u001b[39;00m\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;66;03m# if tensor.ndim > 2:\u001b[39;00m\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;66;03m#     tensor = tensor.squeeze(0)\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;66;03m# elif tensor.ndim < 2:\u001b[39;00m\n\u001b[1;32m    714\u001b[0m     \u001b[38;5;66;03m#     tensor = tensor[None, :]\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: too many dimensions 'str'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [40]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenized_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2894\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.pad\u001b[0;34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, return_attention_mask, return_tensors, verbose)\u001b[0m\n\u001b[1;32m   2891\u001b[0m             batch_outputs[key] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   2892\u001b[0m         batch_outputs[key]\u001b[38;5;241m.\u001b[39mappend(value)\n\u001b[0;32m-> 2894\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBatchEncoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:209\u001b[0m, in \u001b[0;36mBatchEncoding.__init__\u001b[0;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[1;32m    205\u001b[0m     n_sequences \u001b[38;5;241m=\u001b[39m encoding[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_sequences\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_sequences \u001b[38;5;241m=\u001b[39m n_sequences\n\u001b[0;32m--> 209\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:723\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverflowing_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    719\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    720\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to create tensor returning overflowing tokens of different lengths. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    721\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease see if a fast version of this tokenizer is available to have this feature available.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    722\u001b[0m             )\n\u001b[0;32m--> 723\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    724\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to create tensor, you should probably activate truncation and/or padding \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    725\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpadding=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtruncation=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to have batched tensors with the same length.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    726\u001b[0m         )\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length."
     ]
    }
   ],
   "source": [
    "tokenizer.pad(tokenized_dataset['train'][:2], return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a0c6be89",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bc20b6d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:707\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor(value):\n\u001b[0;32m--> 707\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;66;03m# Removing this for now in favor of controlling the shape with `prepend_batch_axis`\u001b[39;00m\n\u001b[1;32m    710\u001b[0m     \u001b[38;5;66;03m# # at-least2d\u001b[39;00m\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;66;03m# if tensor.ndim > 2:\u001b[39;00m\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;66;03m#     tensor = tensor.squeeze(0)\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;66;03m# elif tensor.ndim < 2:\u001b[39;00m\n\u001b[1;32m    714\u001b[0m     \u001b[38;5;66;03m#     tensor = tensor[None, :]\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: too many dimensions 'str'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [38]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdata_collator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtokenized_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [35]\u001b[0m, in \u001b[0;36mDataCollatorWithPadding.__call__\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, features):\n\u001b[0;32m---> 35\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[1;32m     43\u001b[0m         batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2894\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.pad\u001b[0;34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, return_attention_mask, return_tensors, verbose)\u001b[0m\n\u001b[1;32m   2891\u001b[0m             batch_outputs[key] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   2892\u001b[0m         batch_outputs[key]\u001b[38;5;241m.\u001b[39mappend(value)\n\u001b[0;32m-> 2894\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBatchEncoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:209\u001b[0m, in \u001b[0;36mBatchEncoding.__init__\u001b[0;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[1;32m    205\u001b[0m     n_sequences \u001b[38;5;241m=\u001b[39m encoding[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_sequences\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_sequences \u001b[38;5;241m=\u001b[39m n_sequences\n\u001b[0;32m--> 209\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:723\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverflowing_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    719\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    720\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to create tensor returning overflowing tokens of different lengths. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    721\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease see if a fast version of this tokenizer is available to have this feature available.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    722\u001b[0m             )\n\u001b[0;32m--> 723\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    724\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to create tensor, you should probably activate truncation and/or padding \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    725\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpadding=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtruncation=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to have batched tensors with the same length.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    726\u001b[0m         )\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length."
     ]
    }
   ],
   "source": [
    "data_collator([tokenized_dataset['train'][:2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d564f7c",
   "metadata": {},
   "source": [
    "### Creating Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ed3a8d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, texts, labels=None):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        inp = tokenizer(text, truncation=True)\n",
    "        \n",
    "        label = None\n",
    "        if self.labels is not None:\n",
    "            label = self.labels[idx]\n",
    "            \n",
    "        inp['label'] = label\n",
    "        return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "12720e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet('../data/train_UPD.parquet')\n",
    "\n",
    "train_dataset = CustomDataset(list(df['discourse_text_UPD'])[:10], list(df['labels'])[:10])\n",
    "val_dataset = CustomDataset(list(df['discourse_text_UPD'])[-5:], list(df['labels'])[-5:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "36e752dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "417174f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [17250, 11, 1312, 1101, 19068, 11, 1312, 1101, 1016, 284, 307, 3597, 546, 703, 428, 1986, 319, 8706, 318, 257, 3288, 1956, 687, 393, 611, 612, 318, 1204, 319, 8706, 326, 925, 340, 13, 383, 1621, 318, 546, 703, 8884, 1718, 257, 4286, 286, 8706, 290, 257, 1986, 373, 1775, 319, 262, 5440, 13, 8884, 1595, 470, 760, 611, 262, 1956, 687, 373, 2727, 416, 1204, 319, 8706, 11, 393, 611, 340, 318, 655, 257, 3288, 1956, 687, 13], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'label': 1}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f2c8582d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "49dae169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(inps):\n",
    "    all_inps = {\n",
    "        'input_ids': [],\n",
    "        'attention_mask': [],\n",
    "        'label': [],\n",
    "    }\n",
    "    for x in inps:\n",
    "        all_inps['input_ids'].append(x['input_ids'])\n",
    "        all_inps['attention_mask'].append(x['attention_mask'])\n",
    "        all_inps['label'].append([x['label']])\n",
    "        \n",
    "    return tokenizer.pad(inps, return_tensors='pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f277e4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da10afb1",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "de5a3be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "12305f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "LR = 2e-5\n",
    "TRAIN_BATCH_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8d5fb290",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "optimizer_parameters = [\n",
    "    {\n",
    "        \"params\": [\n",
    "            p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": 0.001,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [\n",
    "            p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n",
    "\n",
    "num_train_steps = int(len(train_dataset) / TRAIN_BATCH_SIZE * EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "59f3e95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CRITERION = nn.CrossEntropyLoss()\n",
    "OPTIMIZER = AdamW(optimizer_parameters, lr=LR)\n",
    "\n",
    "SCHEDULER = get_linear_schedule_with_warmup(\n",
    "    OPTIMIZER, num_warmup_steps=0, num_training_steps=num_train_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafaf61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8fcb2903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data, criterion):\n",
    "    label = data.pop('label')\n",
    "    y_pred = model(**data).logits\n",
    "    return criterion(y_pred, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6396a5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "48afb999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.3194, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(next(iter(train_dataloader)), CRITERION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62e0784",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_val_loss = None\n",
    "for epoch in range(1, epochs + 1):\n",
    "    progress_bar = tqdm(\n",
    "        total=len(train_dataloader) + len(val_dataloader),\n",
    "        desc=f\"Epoch {epoch}/{EPOCHS}\",\n",
    "        leave=True,\n",
    "    )\n",
    "    # Training\n",
    "    train_loss = []\n",
    "    OPTIMIZER.zero_grad()\n",
    "    self.train()\n",
    "    for data in train_dataloader:\n",
    "        loss = evaluate(data, CRITERION)\n",
    "        loss.backward()\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "        OPTIMIZER.step()\n",
    "        OPTIMIZER.zero_grad()\n",
    "        progress_bar.set_postfix({\"loss\": sum(train_loss) / len(train_loss)})\n",
    "        progress_bar.update()\n",
    "\n",
    "    # Validation\n",
    "    val_loss = []\n",
    "    self.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in val_dataloader:\n",
    "            loss = self.evaluate(data, CRITERION)\n",
    "            val_loss.append(loss.item())\n",
    "            progress_bar.set_postfix(\n",
    "                {\n",
    "                    \"loss\": sum(train_loss) / len(train_loss),\n",
    "                    \"val loss\": sum(val_loss) / len(val_loss),\n",
    "                }\n",
    "            )\n",
    "            progress_bar.update()\n",
    "\n",
    "    progress_bar.close()\n",
    "    val_loss = sum(val_loss) / len(val_loss)\n",
    "\n",
    "    if SCHEDULER is not None:\n",
    "        SCHEDULER.step(val_loss)\n",
    "\n",
    "    if prev_val_loss is None or prev_val_loss > val_loss:\n",
    "        prev_val_loss = val_loss\n",
    "        countdown_patience = patience\n",
    "        print(f'Min val loss: {prev_val_loss} at Epoch: {epoch}')\n",
    "        if save_model:\n",
    "            torch.save(self.state_dict(), f\"{model_path}.pt\")\n",
    "    else:\n",
    "        if countdown_patience == 0:\n",
    "            break\n",
    "        else:\n",
    "            countdown_patience -= 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
